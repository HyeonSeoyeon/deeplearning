# 인공지능 기초를 위한 FAQ (1-13번, 28-32번)
---
![Image](https://github.com/user-attachments/assets/ea4a5397-e7bc-4d97-8ba7-22fa6b91d59a)
![Image](https://github.com/user-attachments/assets/67932b51-70a6-49b1-9600-d4c9ceca7fce)
![Image](https://github.com/user-attachments/assets/b5884e9c-8bec-4447-bc28-c59f4a271902)
---
1. 인공지능에서 지능에 해당하는 기능은 무엇인가?<br>
  생각하고 판단하는 능력. 즉, 인간의 두뇌처럼 정보를 이해하고, 결정을 내리는 것을 의미한다.

2. 인공지능의 종류 3가지에 대해서 설명하시오. (지도학습, 반지도학습, 강화학습)<br>
  지도학습: 입력(X)와 정답(y)이 둘 다 주어진 상태에서 학습하는 방법.<br>
  즉, 이미 답이 있는 데이터를 가지고 모델을 학습시키는 방식이다.<br>
  모델은 입력 데이터를 보고 정답(y)를 예측하도록 훈련된다. (대표적인 모델: DT, RF, SVM, LR)<br><br>
  반자동학습: 입력 데이터(X)는 많은데, 정답(y)는 일부만 있는 경우에서 학습하는 방법.<br>
  지도학습과 비지도학습(정답 없이 패턴만 찾는 방식)의 중간 형태이다.<br>
  ex) 인터넷에서 수집한 뉴스 기사 분류: 뉴스 기사(입력)은 많지만, 라벨(정치, 경제, 스포츠 등)은 일부.<br><br>
  강화학습: 보상을 주면서 스스로 학습하는 방식.<br>
  즉, 사람처럼 시행착오를 거치면서 행동을 하면 보상을 받고, 그 보상을 최대화하는 점점 더 좋은 선택을 하도록 학습하는 것이다.<br>

3. 전통적인 프로그래밍 방법과 인공지능 프로그램의 차이점은 무엇인가?<br>
  전통적인 프로그래밍은 사람이 규칙을 직접 입력하여 입력->규칙->출력(정답) 과정을 말하고,<br>
  인공지능 프로그램은 데이터에서 규칙을 학습하여 입력+출력(정답)->학습->규칙 생성을 하여 새로운 데이터를 입력했을 때, 정답을 예측하여 출력하는 것이다.<br>
  전통적인 프로그래밍의 예는 if-else 조건문이 있고, 인공지능 프로그램의 예는 머신러닝과 딥러닝 모델이 있다.<br>
  
4. 딥러닝과 머신러닝의 차이점은 무엇인가?<br>
  머신러닝(ML): AI중에서 데이터를 기반으로 학습하는 방식.<br>
  사람이 직접 규칙을 짜는 대신, 데이터에서 패턴을 찾아 학습한다. -> 특징을 먼저 추출하고 모델에 넣는다.<br>
  input -> feature extraction -> classification -> output<br><br>
  딥러닝(DL): 머신러닝 중에서도 신경망(Neural Network)을 활용한 모델.<br>
  특징을 사람이 직접 추출하지 않아도 됨. -> 자동으로 특징 추출.<br>
  따라서 raw 데이터를 넣고 모델에서 분류한다.<br>
  input -> classification -> output<br>

5. Classification(분류)과 Regression(회귀)의 주된 차이점은?<br>
  Classification은 이산적인 값(카테고리)를 맞추는 것이고, Regression(회귀)는 연속적인 값(숫자)를 예측하는 것이다.<br>

6. 머신러닝에서 차원의 저주(curse of dimensionality)란?<br>
  머신러닝에서 데이터가 가진 속성 즉, 특성을 '차원'이라고 하는데 차원이 증가하여 데이터가 너무 넓게 퍼져서 모델이 제대로 학습하지 못하는 현상을 말한다.<br>

7. Dimensionality Reduction(차원 축소)는 왜 필요한가?<br>
  데이터가 너무 많이 퍼져서 모델 학습을 저하시키는 차원의 저주 문제와 과적합을 유발하는 노이즈 문제, 그리고 계산 비용 절감을 해결하기 위해 필요하다.<br>

8. Ridge와 Lasso의 공통점과 차이점? (Regularization, 규제, Scaling)<br>
   공통점: 둘 다 정규화 방법으로, 모델의 복잡도를 줄여 과적합을 방지한다.<br>
   쉽게 말해서, 머신러닝 모델이 훈련세트를 너무 과도하게 학습하지 못하도록 훼방하는 것을 말하는데, 모델이 훈련세트에 과적합되지 않도록 만든다.<br>
   둘 다 선형회귀 모델에 Regularization을 추가한 모델이며, sklearn.linear_model 패키지 안에 있다. 또한 둘 다 계수(가중치)의 크기를 줄인다.<br><br>
   차이점: Ridge는 가중치(계수)를 작게 만들지만 0은 아니다. 비교적 효과가 좋아 널리 사용된다.<br>
   Lasso는 릿지와 달리 가중치(계수)값을 아예 0으로 만들 수 있다.<br>

9. Overfitting(과적합) vs Underfitting(과소적합)<br>
    Overfitting: 훈련 데이터에 너무 집착해서, 새로운 데이터에 적용하면 성능이 안 좋아지는 경우.<br>
    모델의 훈련세트 성능이 테스트세트 성능보다 훨씬 높을 때 일어나는 것으로, 모델이 훈련세트에 너무 집착해서 데이터에 내재된 거시적인 패턴을 감지하지 못한다.<br><br>
    Underfitting: 모델이 너무 단순해서 데이터의 패턴을 제대로 학습하지 못하는 경우.<br>
    훈련세트와 테스트세트 성능이 모두 동일하게 낮거나 테스트세트 성능이 오히려 더 높을 때 일어난다.<br>

10. Feature Engineering과 Feature Selection의 차이점은?<br>
    Feature Engineering(특성 공학): 기존의 특성을 사용해 새로운 특성을 만드는 과정.<br>
    ex) 키, 몸무게 -> BMI 라는 새로운 특성 생성.<br><br>
    Feature Selection(특성 선택): 중요한 특성만 고르는 과정. (필요없는 특성 없애기)<br>
    ex) 키, 몸무게, 눈 색깔 -> 눈 색깔은 예측에 필요 없음. -> 제거.<br>

11. 전처리(Processing)의 목적과 방법? (노이즈, 이상치, 결측치)<br>
  목적: 모델이 올바르게 학습하도록 데이터를 깨끗하게 정리하기 위함.<br>
  데이터에 오류(노이즈, 이상치, 결측치)를 정리하고 가공해 모델 성능을 좋아지게 하기 위함.<br><br>
  방법: 결측치 처리(평균값, 중간값으로 채우거나 삭제), 이상치 제거(너무 크거나 작은 값을 제거), 정규화 & 표준화(값의 범위를 맞추어 특정 변수가 모델을 지배하지 않도록 함), 범주형 데이터 처리(One-HotEncoding 등을 사용해 숫자로 변환)<br>

12. EDA(Exploratory Data Analysis)란?<br>
    데이터에 이상한 값이 있는지 확인하고 변수 간의 관계를 분석해서 의미있는 패턴을 찾기 위하여 데이터를 시각화하고 통계를 확인하여 패턴과 특징을 파악하는 과정이다.<br>
    데이터 분포 확인(df.describe()), 결측치 확인(df.isnull().sum()), 변수 간 관계 확인(sns.pairplot(df)), 상관관계 분석(df.sort())등이 있다.<br>

13. 회귀에서 절편과 기울기가 의미하는 바는? 딥러닝과 어떻게 연관되는가?<br>
    회귀에서 기울기(w)는 입력값이 변할 때 결과값이 얼마나 변하는지, 절편(b)는 기본적으로 시작하는 값을 의미한다.<br>
    이러한 파라미터(w, b)를 조정하여 데이터에 가장 적합한 선을 찾는 과정이 '학습'이며, 이를 통해 훈련 데이터에서 y=wx+b라는 최적의 직선을 찾는 것이 회귀 모델의 목표이다.<br>
    딥러닝의 뉴런도 선형회귀와 유사한 방식(입력값 x 가중치 + 바이어스)으로 동작하며 예측을 수행한다.<br>

28. 결정트리에서 불순도(Impurity) - 지니계수(Gini Index)란 무엇인가?<br>
    불순도란, 분류하려는 데이터 집합에서 서로 다른 클래스(범주)가 섞여있는 정도를 나타내는 지표이다.<br>
    즉, 데이터가 섞여있는 정도를 나타내는 값이다. 데이터가 한 클래스만 있다면 불순도는 0, 데이터가 여러 클래스 섞여있다면 불순도는 높아진다.<br><br>
    지니계수란, 불순도를 측정하는 지표로서 통계적 분산 정도를 정량화하여 표현한 값이다.<br>
    0과 1사이의 값을 가지며 지니계수가 높을수록 잘 분류되지 못한 것이다.<br>
    결정트리는 불순도를 최소화하기 위해 지니계수가 가장 낮아지는 방향으로 데이터를 분류한다.<br>

29. 앙상블이란 무엇인가?<br>
  앙상블이란 여러 개의 모델을 조합해서 더 좋은 성능을 내는 모델을 만드는 기법이다.<br>
  여러 모델의 결과를 평균내거나 투표해서 최종 결과를 내린다.<br>
  대표적인 앙상블 방법으로는 Bagging(배깅)과 Boosting(부스팅)이 있다.<br>
  배깅은 여러 개의 모델을 독립적으로 훈련해서 결과를 평균내는 것이고,<br>
  부스팅은 이전 모델의 틀린 부분을 집중적으로 학습하면서 개선하는 방법이다.<br>

30. 부트스트랩핑(bootstraping)이란 무엇인가?<br>
  부트스트랩핑이란 데이터 샘플을 여러번 뽑아서(복원 추출) 여러 개의 모델을 학습하는 기법이다.<br>
  데이터에서 랜덤하게 복원 추출(뽑은 데이터도 다시 뽑힐 수 있음) -> 여러 개의 샘플을 만들어서 각각 모델을 학습 -> 결과를 종합해서 최종 예측을 수행한다.<br>
  부트스트랩핑은 배깅(Bagging)과 랜덤 포레스트에서 많이 사용된다.<br>

31. 배깅(Bagging)이란?
  서로 다른 모델을 만들기 위해 랜덤 복원 샘플링 방법으로 훈련 데이터를 다르게 해주는 작업이다.<br>
  배깅의 특징으로는 병렬적 처리(모델 사이 관계가 독립적, 병렬적임)라는 것이고,<br>
  대표적인 배깅의 앙상블 기법으로는 '랜덤 포레스트' 기법이 있다.<br>

32. 주성분 분석(PCA)이란 무엇인가?
    주성분 분석은 차원 축소 알고리즘의 하나로 데이터에서 가장 분산이 큰 방향을 찾는 방법이다.<br>
    이런 방향을 주성분이라고 부르는데, 원본 데이터를 주성분에 투영하여 새로운 특성을 만들 수 있다.<br>


   

  
